# Requirements Document

## Introduction

AutoUX is an AI-powered UX analysis system that uses LLM technology to analyze various log formats and identify UX issues including latency, accessibility, contrast, and JavaScript errors. The system features Web3 integration for decentralized verification of analysis reports on Sepolia testnet, providing cryptographic proof of report integrity while maintaining user privacy. The application includes a modern, hackathon-ready UI with gamification elements and comprehensive recommendations based on WCAG and Web Vitals standards.

## Glossary

- **AutoUX System**: The complete system comprising React frontend, Node.js/Express backend, LLM analyzer, and Web3 integration
- **UX Issue**: A problem detected in logs that affects user experience (latency, accessibility, contrast, JavaScript errors)
- **AI Report**: A structured JSON document generated by the LLM containing detected issues, recommendations, and UX score
- **Log Entry**: An entry in various formats (JSON, NDJSON, CSV, XML, HTML, HAR, TXT, LOG) containing UX event information
- **Frontend Application**: The React user interface built with Vite featuring modern UI/UX and Web3 capabilities
- **Backend Service**: The Node.js/Express server that processes logs via LLM and manages API endpoints
- **LLM Analyzer**: The OpenRouter-powered AI service using KAT-Coder-Pro model for intelligent log analysis
- **Web3 Module**: The blockchain integration layer for on-chain proof anchoring and verification on Sepolia testnet
- **Smart Contract**: The AutoUXRegistry Solidity contract deployed on Sepolia for hash storage and verification
- **Hash Anchoring**: The process of storing a SHA-256 hash of the AI report on-chain for integrity proof

## Requirements

### Requirement 1: Multi-Format Log Analysis with LLM

**User Story:** As a developer, I want to upload logs in various formats and have them analyzed by AI to automatically detect UX issues, so that I can quickly identify improvement areas in my application.

#### Acceptance Criteria

1. WHEN a user uploads a log file, THE Backend Service SHALL accept JSON, NDJSON, CSV, XML, HTML, HAR, TXT, and LOG formats
2. WHEN the Backend Service receives a log file, THE Backend Service SHALL parse the file format automatically
3. WHEN the Backend Service parses logs successfully, THE Backend Service SHALL send the parsed data to OpenRouter API using model kwaipilot/kat-coder-pro:free
4. WHEN the LLM Analyzer processes logs, THE LLM Analyzer SHALL return a structured AI Report containing issues array, categories, severities, recommendations, and global UX score
5. WHEN the LLM Analyzer detects issues, THE AI Report SHALL include both JSON and Markdown formatted outputs

### Requirement 2: Modern UI/UX with Dashboard and Visualizations

**User Story:** As a developer, I want to visualize detected UX issues in a modern, engaging interface with animations and gamification elements, so that I can understand issues and their impacts at a glance.

#### Acceptance Criteria

1. WHEN the Frontend Application loads without a report, THE Frontend Application SHALL display a modern empty state with engaging CTA and file upload drop-zone
2. WHEN a user uploads logs, THE Frontend Application SHALL display an animated progress indicator and loading states
3. WHEN the AI Report is ready, THE Frontend Application SHALL display an animated UX Score gauge (0-100) with color grading (90-100 green/Excellent, 70-89 amber/Fair, <70 red/Critical) and emojis
4. WHEN the AI Report is displayed, THE Frontend Application SHALL show a summary sidebar with total issues, categories breakdown, and quick filters by severity and type
5. WHEN the user views the dashboard, THE Frontend Application SHALL include animated gradient header, pulse AI-powered indicator, and smooth fade transitions between states

### Requirement 3: AI-Powered Recommendations with Standards References

**User Story:** As a developer, I want to receive prioritized, actionable recommendations with explanations and standards references, so that I understand why issues matter and how to fix them properly.

#### Acceptance Criteria

1. WHEN the LLM Analyzer generates recommendations, THE AI Report SHALL include prioritized actions with explanations of impact
2. WHEN recommendations are displayed, THE Frontend Application SHALL show WCAG 2.2 references (1.4.3 Contrast, 1.1.1 Alt text, 2.1.1 Keyboard, 4.1.2 ARIA) for accessibility issues
3. WHEN recommendations are displayed, THE Frontend Application SHALL show Web Vitals references (LCP, FID, CLS) for performance issues
4. WHEN the user views recommendations, THE Frontend Application SHALL provide a tab switcher between Markdown and JSON formats
5. WHEN recommendations are generated, THE AI Report SHALL explain the "why" behind each recommendation with context-specific guidance

### Requirement 4: Web3 Integration for On-Chain Proof

**User Story:** As a developer, I want to anchor my AI report hash on Sepolia blockchain and verify its integrity, so that I have cryptographic proof that my report hasn't been tampered with while keeping my logs private.

#### Acceptance Criteria

1. WHEN the user connects their wallet, THE Web3 Module SHALL request MetaMask connection and display the connected address in abbreviated format (0x1234...5678)
2. WHEN the user clicks "Anchor Hash", THE Web3 Module SHALL compute SHA-256 hash of the AI Report and call the Smart Contract storeHash function on Sepolia testnet
3. WHEN the hash is anchored, THE Smart Contract SHALL emit a HashStored event with hash, sender address, and timestamp
4. WHEN the user clicks "Verify", THE Web3 Module SHALL compute the report hash and call the Smart Contract verifyHash function to check if it matches the on-chain record
5. WHEN verification succeeds, THE Frontend Application SHALL display a green "Verified on-chain" badge with Etherscan link tooltip

### Requirement 5: Web3 Enhanced Features

**User Story:** As a developer, I want to view my on-chain anchor history, mint NFT badges for my reports, and share verification proofs via QR codes, so that I can showcase my UX quality achievements.

#### Acceptance Criteria

1. WHEN the user views the "Your On-Chain Anchors" section, THE Frontend Application SHALL fetch past HashStored events from Sepolia and display all hashes anchored by the user with date, time, TX link, and associated score
2. WHEN the user clicks "Mint UX Badge NFT", THE Web3 Module SHALL mint an ERC-721 NFT with metadata (score, hash, timestamp) stored on IPFS
3. WHEN the NFT is minted, THE Frontend Application SHALL display the NFT metadata URL and link to view on OpenSea testnet
4. WHEN the user clicks "Share UX Proof", THE Frontend Application SHALL generate a QR code containing score, hash, and verification URL
5. WHEN Web3 features are enabled, THE Frontend Application SHALL display a "Web3 Enabled" badge in the header and Web3 section in the footer with contract link to Etherscan

### Requirement 6: Performance and Responsiveness

**User Story:** As a developer, I want the application to be fast, responsive on mobile devices, and cache results intelligently, so that I have a smooth experience regardless of device or network conditions.

#### Acceptance Criteria

1. WHEN a user uploads a file, THE Frontend Application SHALL implement debounce on the file uploader to prevent multiple simultaneous uploads
2. WHEN the Frontend Application loads components, THE Frontend Application SHALL use React Suspense and lazy loading for code splitting
3. WHEN the LLM Analyzer returns a report, THE Frontend Application SHALL cache the response in sessionStorage to avoid redundant API calls
4. WHEN the application is viewed on mobile, THE Frontend Application SHALL display full-width upload cards (90vw), collapsible footer tabs, and a sticky upload button at the bottom
5. WHEN the application is viewed on any device, THE Frontend Application SHALL ensure all interactive elements are touch-friendly and keyboard accessible

### Requirement 7: Clean Architecture and Production-Ready Code

**User Story:** As a developer, I want the codebase to be clean, well-structured, and production-ready with no mock data or placeholder content, so that I can deploy it confidently for the hackathon demo.

#### Acceptance Criteria

1. WHEN the codebase is reviewed, THE AutoUX System SHALL contain no mock data files (demo_fix.json, sample logs, sample issues, sample fixspecs)
2. WHEN the application runs, THE AutoUX System SHALL use only real LLM-generated analysis from OpenRouter with no fallback to mock data
3. WHEN the codebase is reviewed, THE AutoUX System SHALL contain all text in English with no French language strings
4. WHEN the folder structure is reviewed, THE AutoUX System SHALL have a clean workspace structure with backend and frontend folders properly organized
5. WHEN the code is reviewed, THE AutoUX System SHALL follow consistent coding standards with readable, maintainable code throughout

### Requirement 8: Security and Privacy

**User Story:** As a developer, I want my log data to remain private while still being able to prove report integrity on-chain, so that I can maintain confidentiality while having verifiable results.

#### Acceptance Criteria

1. WHEN logs are processed, THE Backend Service SHALL never send raw log data to the blockchain
2. WHEN a hash is anchored, THE Web3 Module SHALL only store the SHA-256 hash on-chain, keeping the actual report and logs local
3. WHEN the Smart Contract is called, THE Smart Contract SHALL validate that the hash is in bytes32 format before storing
4. WHEN Web3 operations fail, THE Frontend Application SHALL display user-friendly error messages without exposing sensitive technical details
5. WHEN transactions are pending, THE Frontend Application SHALL show loading states and allow retry logic for failed transactions with proper error handling
